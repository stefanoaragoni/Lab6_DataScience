{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratorio 6 - Generative Adversarial Network\n",
    "Stefano Aragoni, Carol Arévalo\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica se diseñó una Generative Adversarial Network (GAN) con el propósito de poder generar imágenes artificiales que imiten la distribución de los datos originales Para esto, fue necesario diseñar una red neuronal que fuera capaz de generar imágenes, y otra red neuronal que fuera capaz de diferenciar entre imágenes reales y generadas. \n",
    "\n",
    "A continuación se muestra el código utilizado para la creación de la GAN, así como los resultados obtenidos.\n",
    "\n",
    "------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importar librerías\n",
    "\n",
    "Como primer paso, se importaron las librerías necesarias para la creación de la GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Reshape, Dropout, LeakyReLU, Flatten, BatchNormalization, Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### **Preparación de Datos**\n",
    "\n",
    "##### Cargar el dataset de CelebA y Preprocesamiento de Datos \n",
    "\n",
    "Para iniciar, se descargó el dataset de CelebA. Este conjunto de datos consta de más de 200,000 imágenes a color, de 128 X 128 X 3 c/u. A continuación se muestra la ubicación de las imágenes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direcciones de los archivos\n",
    "fotos_dir = 'archive/img_align_celeba/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la librería de Keras, se cargaron las imágenes por batches.\n",
    "\n",
    "Asimismo, se les aplicó un preprocesamiento, el cual consistió en normalizar los valores de los pixeles de las imágenes, recortarlas y redimensionarlas a 64 X 64 X 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Tamaño de las imágenes\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer las imagenes -> Función recomendada por Prof. Luis Furlan.\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,                    # PRE-PROCESAMIENTO: Normalizar los valores de los pixeles\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% de las imágenes para validación\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 162080 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Carga las imagenes de entrenamiento\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    fotos_dir,\n",
    "    target_size=(img_size, img_size),        # PRE-PROCESAMIENTO: RECORTAR Y REDIMENSIONAR IMÁGENES\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40519 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Carga las imagenes de validación\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    fotos_dir,\n",
    "    target_size=(img_size, img_size),        # PRE-PROCESAMIENTO: RECORTAR Y REDIMENSIONAR IMÁGENES\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  \n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### **Implementación de la GAN**\n",
    "\n",
    "##### Diseño del generador y el discriminador\n",
    "\n",
    "A continuación se demuestra el modelo del <font color=orange>generador</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Tamaño de la capa que va hacia el Generador\n",
    "tamanio_codificacion = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "generador = Sequential()\n",
    "generador.add(Dense(7 * 7 * 128, input_shape = [tamanio_codificacion]))\n",
    "generador.add(Reshape([7, 7, 128]))\n",
    "generador.add(BatchNormalization())\n",
    "generador.add(Conv2DTranspose(64, \n",
    "                              kernel_size = 5, \n",
    "                              strides = 2, \n",
    "                              padding = \"same\",\n",
    "                              activation = \"relu\"))\n",
    "generador.add(BatchNormalization())\n",
    "generador.add(Conv2DTranspose(1, \n",
    "                              kernel_size = 5, \n",
    "                              strides = 2, \n",
    "                              padding = \"same\",\n",
    "                              activation = \"tanh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se demuestra el modelo del <font color=orange>discriminador</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminador = Sequential()\n",
    "discriminador.add(Conv2D(64, \n",
    "                         kernel_size = 5, \n",
    "                         strides = 2, \n",
    "                         padding = \"same\",\n",
    "                         activation = LeakyReLU(0.3),\n",
    "                         input_shape = [28, 28, 1]))\n",
    "discriminador.add(Dropout(0.5))\n",
    "discriminador.add(Conv2D(128, \n",
    "                         kernel_size = 5, \n",
    "                         strides = 2, \n",
    "                         padding = \"same\",\n",
    "                         activation = LeakyReLU(0.3)))\n",
    "discriminador.add(Dropout(0.5))\n",
    "discriminador.add(Flatten())\n",
    "discriminador.add(Dense(1, \n",
    "                        activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definición de funciones de pérdida y optimizadores\n",
    "\n",
    "Con los modelos listos, se procedió a definir las funciones de pérdida y los optimizadores. Esto con el propósito de poder entrenar la GAN. Más específicamente, se utilizó la función de <font color=orange>Binary Cross Entropy</font> (BCE) como función de pérdida, y el <font color=orange>optimizador Adam</font>. \n",
    "\n",
    "Asimismo, se indicó que el discriminador no se entrenaría durante el entrenamiento de la GAN, ya que el objetivo es entrenar al generador para que engañe al discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = Sequential([generador, discriminador])\n",
    "\n",
    "discriminador.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminador.trainable = False\n",
    "\n",
    "GAN.compile(loss = \"binary_crossentropy\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### **Entrenamiento de la GAN**\n",
    "\n",
    "##### Implementación del bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualización de los resultados durante el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "### **Reflexión**\n",
    "\n",
    "Reflexione sobre lo aprendido en la sesión teórica y cómo se aplicó en el laboratorio. Algunos \n",
    "puntos que podrían considerar en su reflexión incluyen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Qué conceptos de la teoría encontraron más desafiantes y por qué?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Cómo les ayudó el laboratorio a consolidar o entender mejor estos conceptos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ¿Qué aplicaciones potenciales ven para las GANs en la industria o en la investigación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ¿Qué limitaciones o preocupaciones éticas pueden identificar en el uso de GANs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ¿Cómo se sienten con respecto a la implementación y entrenamiento de GANs después de la  experiencia práctica?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
